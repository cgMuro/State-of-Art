DALL•E is a model by OpenAI that generates images from text descriptions.                                                 
Trained with a dataset of text–image pairs collected on the internet, the model is made of a discrete Variational AutoEncoder (dVAE) and a decoder-only sparse transformer. The latter takes in the image embedding generated by the dVAE and models the text and image tokens as a single stream of data.

### Architecture and Methods

<p align='center'>Discrete Variational AutoEncoder (dVAE)</p>

* It's made of an encoder and a decoder. Both are convolutional ResNets with bottleneck-style blocks
* It's used to compress 256x256 RGB images into a grid of 32x32 image tokens with a visual codebook of 8192 values

<br>

<p align='center'>Autoregressive Sparse Transformer</p>

* The sparse transformer is a modified version of the vanilla transformer in which different types of masks and techniques are used to speed up training and increase the length of sequences the transformer can attend to. More info [here](https://arxiv.org/abs/1904.10509)
* Autoregressive means that the models take in past values to predict future values
* It takes in the 256-BPE-encoded text tokens and the 1024 (32x32) image tokens and models the joint distribution over them


<br>
<br>

## Resources:
* Paper: [*Zero-Shot Text-to-Image Generation*](https://arxiv.org/abs/2102.12092) (**Aditya Ramesh**, **Mikhail Pavlov**, **Gabriel Goh**, **Scott Gray**, **Chelsea Voss**, **Alec Radford**, **Mark Chen**, **Ilya Sutskever**)
* [DALL·E: Creating Images from Text](https://openai.com/blog/dall-e/) (**OpenAI Blog**)
* [OpenAI DALL·E: Creating Images from Text (Blog Post Explained)](https://www.youtube.com/watch?v=j4xgkjWlfL4) (**Yannic Kilcher**)
* [openai/DALL-E GitHub](https://github.com/openai/DALL-E) (**OpenAI**)
* [lucidrains/DALLE-pytorch GitHub](https://github.com/lucidrains/DALLE-pytorch) (**lucidrains**)
* Paper: [Generating Long Sequences with Sparse Transformers](https://arxiv.org/abs/1904.10509) (**Rewon Child**, **Scott Gray**, **Alec Radford**, **Ilya Sutskever**)
* [Generative Modeling withSparse Transformers](https://openai.com/blog/sparse-transformer/) (**OpenAI Blog**)
* [openai/sparse_attention GitHub](https://github.com/openai/sparse_attention) (**OpenAI**)
