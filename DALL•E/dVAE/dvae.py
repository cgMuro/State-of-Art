import torch
import torch.nn as nn
from encoder import Encoder
from decoder import Decoder

# Define entire discrete Variational Auto Encoder
class dVAE(nn.Module):
    def __init__(
        self, 
        in_planes: int, 
        hidden_planes: int, 
        out_planes: int,
        blocks_per_group: int,
        vocab_size: int = 8192
    ):
        super().__init__()

        self.encoder = Encoder(in_planes, hidden_planes, out_planes, blocks_per_group, vocab_size)
        self.decoder = Decoder(in_planes, hidden_planes, out_planes, blocks_per_group, vocab_size)

    def forward(self, x: torch.Tensor, temperature: float) -> torch.Tensor:
        # Encoder
        encoder_out = self.encoder(x)
        # To optimize the distribution over the 32 × 32 image tokens generated by the dVAE encoder 
        # we use the gumbel-softmax relaxation, where the relaxation becomes tight as the temperature τ → 0
        out = nn.functional.gumbel_softmax(encoder_out, tau=temperature, hard=False, dim=1)
        # Decoder
        decoder_out = self.decoder(out)

        return encoder_out, decoder_out
