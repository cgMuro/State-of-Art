## Resources:
* [Paper](https://arxiv.org/abs/1706.03762) (**Ashish Vaswani**, **Noam Shazeer**, **Niki Parmar**, **Jakob Uszkoreit**, **Llion Jones**, **Aidan N. Gomez**, **Lukasz Kaiser**, **Illia Polosukhin**)
* [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) (**Jay Alammar**)
* [Visualizing A Neural Machine Translation Model](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) (**Jay Alammar**)
* [Sequence-to-Sequence Modeling with nn.Transformer and TorchText](https://pytorch.org/tutorials/beginner/transformer_tutorial.html) (**PyTorch**)
* [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html) (**Guillaume Klein**, **Yoon Kim**, **Yuntian Deng**, **Jean Senellart**, **Alexander M. Rush**)
* [AI Language Models & Transformers](https://www.youtube.com/watch?v=rURRYI66E54) (**Computerphile**)
* [Transformer Neural Networks - EXPLAINED! (Attention is all you need)](https://www.youtube.com/watch?v=TQQlZhbC5ps) (**CodeEmporium**)
* [Attention Is All You Need](https://www.youtube.com/watch?v=iDulhoQ2pro) (**Yannic Kilcher**)

<br>

![Transformer architecture image](https://miro.medium.com/max/1090/1*HunNdlTmoPj8EKpl-jqvBA.png)

